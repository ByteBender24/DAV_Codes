{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "by_LbyiQi_10"
   },
   "source": [
    "Ensemble learning can be applied to any dataset to improve model performance. Here are three general ensemble learning techniques:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7WVAZq7jJAc"
   },
   "source": [
    "1. Bagging (Bootstrap Aggregating)\n",
    "Works well to reduce variance and prevent overfitting.\n",
    "Common algorithm: Random Forest\n",
    "# Suitable for both classification and regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qv_jy3TTi44l"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y47wDOT3jWuz"
   },
   "source": [
    "2. Boosting\n",
    "Focuses on reducing bias by training models sequentially.\n",
    "\n",
    "Common algorithms: AdaBoost, Gradient Boosting (GBM), XGBoost, LightGBM, CatBoost\n",
    "\n",
    "Works well with imbalanced datasets and structured data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__TFIU2vk_sa"
   },
   "source": [
    "Implementation using XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4Ebfd8XjUkb"
   },
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train XGBoost model\n",
    "model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Boosting Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbUf2Z2OjbgS"
   },
   "source": [
    "\n",
    "3. Stacking (Stacked Generalization)\n",
    "Combines multiple models (base models) and trains a meta-model on their predictions.\n",
    "Can outperform single models by capturing diverse perspectives.\n",
    "Implementation using Logistic Regression as Meta-Model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gaunCt3jgky"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('svm', SVC(kernel='linear', probability=True)),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=3))\n",
    "]\n",
    "\n",
    "# Define meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Train Stacking Classifier\n",
    "model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Stacking Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeAlxFnqkEJr"
   },
   "source": [
    "# ensemble learning on the Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nV5QmOnskKQC"
   },
   "source": [
    "**Bagging (Bootstrap Aggregating)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MO_1i9VOkG4y",
    "outputId": "096637d1-1978-4e50-c396-ab4f39ee70d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hB5JE6EukPvr"
   },
   "source": [
    "**Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxGQCpkZkRuK",
    "outputId": "ea0297d6-71f1-407c-9b81-f3ae53b415d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting (XGBoost) Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train XGBoost model\n",
    "model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Boosting (XGBoost) Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSTdIWZrkWhz"
   },
   "source": [
    "**Stacking (Stacked Generalization)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQOdiLF7kZ2a",
    "outputId": "1154ea1e-dfb1-4735-8193-7072faeaf022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=3))\n",
    "]\n",
    "\n",
    "# Define meta-model\n",
    "meta_model = SVC(kernel='linear', probability=True)\n",
    "\n",
    "# Train Stacking Classifier\n",
    "model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
